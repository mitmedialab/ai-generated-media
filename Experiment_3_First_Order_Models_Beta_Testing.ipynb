{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment 3_First-Order Models_Beta-Testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdO_RxQZLahB"
      },
      "source": [
        "# ðŸ§ª Experiment 3: First Order Motion Model for Image Animation ðŸ•º"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6NEh6HeYprs"
      },
      "source": [
        "In this assignment, we will create a generative talking head video using First Order Model, which you already learned about from the previous lecture by Aliaksandr Siarohin.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9JXFSCG3jyC"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"text-align: center;\">\n",
        "<a href=\"https://colab.research.google.com/github/mitmedialab/MAS.S60.Fall2020/blob/master/homework/HW2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCDNKsEGLtR6"
      },
      "source": [
        "\n",
        "\n",
        "**Clone repository and install all the requirments***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCMFMJV7K-ag"
      },
      "source": [
        "!git clone https://github.com/AliaksandrSiarohin/first-order-model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8mvHTn2UHAL"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from IPython.display import Image\n",
        "from base64 import b64encode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y8aXooLjuKX"
      },
      "source": [
        "**Open the repository and download example files**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba2DyB20TQcB"
      },
      "source": [
        "%cd first-order-model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPB9ktxpjSSd"
      },
      "source": [
        "import requests\n",
        "#download target image\n",
        "url = 'https://github.com/mitmedialab/MAS.S60.Fall2020/blob/master/homework/hw2-files/monalisa.png?raw=true'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('monalisa.png', 'wb').write(r.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfE7Icv3UD_7"
      },
      "source": [
        "Image('/content/first-order-model/monalisa.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCJpBAGqi0F4"
      },
      "source": [
        "#download driving video\n",
        "url = 'https://github.com/mitmedialab/MAS.S60.Fall2020/blob/master/homework/hw2-files/template_clip.mp4?raw=true'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "open('template_clip.mp4', 'wb').write(r.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI_tXnzIEc9Q"
      },
      "source": [
        "#show driving video\n",
        "mp4 = open('/content/first-order-model/template_clip.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"<video width=400 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PWk_s7ln0cu"
      },
      "source": [
        "**Model Downloading**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nqspJlFwbrp"
      },
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/u/0/uc?id=19d9ZJYAMsNNQZd4AzIWCw4sF1EaNYuJ3&export=download'\n",
        "output = 'vox-cpk.pth.tar'\n",
        "gdown.download(url, output, quiet=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJNjXCiMnzgB"
      },
      "source": [
        "from demo import load_checkpoints\n",
        "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml', \n",
        "                            checkpoint_path='/content/first-order-model/vox-cpk.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT3LKRpMkS4g"
      },
      "source": [
        "**The Visualization function**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxi6-riLOgnm"
      },
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from skimage.transform import resize\n",
        "from IPython.display import HTML\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "source_image = imageio.imread('/content/first-order-model/monalisa.png')\n",
        "driving_video = imageio.mimread('/content/first-order-model/template_clip.mp4')\n",
        "\n",
        "\n",
        "#Resize image and video to 256x256\n",
        "\n",
        "source_image = resize(source_image, (256, 256))[..., :3]\n",
        "driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
        "\n",
        "def display(source, driving, generated=None):\n",
        "    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n",
        "\n",
        "    ims = []\n",
        "    for i in range(len(driving)):\n",
        "        cols = [source]\n",
        "        cols.append(driving[i])\n",
        "        if generated is not None:\n",
        "            cols.append(generated[i])\n",
        "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
        "        plt.axis('off')\n",
        "        ims.append([im])\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
        "    plt.close()\n",
        "    return ani\n",
        "\n",
        "def display_only_output(source, driving, generated=None):\n",
        "    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n",
        "\n",
        "    ims = []\n",
        "    for i in range(len(driving)):\n",
        "        cols = []\n",
        "        #cols.append(driving[i])\n",
        "        if generated is not None:\n",
        "            cols.append(generated[i])\n",
        "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
        "        plt.axis('off')\n",
        "        ims.append([im])\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
        "    plt.close()\n",
        "    return ani\n",
        "\n",
        "def display_output_and_original(source, driving, generated=None):\n",
        "    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n",
        "\n",
        "    ims = []\n",
        "    for i in range(len(driving)):\n",
        "        cols = []\n",
        "        cols.append(driving[i])\n",
        "        #cols.append(driving[i])\n",
        "        if generated is not None:\n",
        "            cols.append(generated[i])\n",
        "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
        "        plt.axis('off')\n",
        "        ims.append([im])\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
        "    plt.close()\n",
        "    return ani"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnXrecuX6_Kw"
      },
      "source": [
        "## Running on your data\n",
        "\n",
        "**First we need to crop a face from both source image and video, while simple graphic editor like paint can be used for cropping from image. Cropping from video is more complicated. You can use ffpmeg for this.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og5HN1nZWZ1a"
      },
      "source": [
        "*If you get an error warning for using your own driving video, sometimes it is because your video has some issue in the first or last frame that makes the algorithm unable to read them. Please use this https://online-video-cutter.com/ to trim the first/last few seconds of your video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GRETp8pXSlQ"
      },
      "source": [
        "*The driving video should have the person's mouth close in the first frame of the video (this serves as the calibration pose for the algorithm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDuNFsABK6k5"
      },
      "source": [
        "from demo import make_animation\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "\n",
        "source_image = imageio.imread('/content/first-order-model/monalisa.png')\n",
        "driving_video = imageio.mimread('/content/first-order-model/template_clip.mp4', memtest=False)\n",
        "\n",
        "\n",
        "#Resize image and video to 256x256\n",
        "source_image = resize(source_image, (256, 256))[..., :3]\n",
        "driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
        "\n",
        "predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True,\n",
        "                             adapt_movement_scale=False)\n",
        "\n",
        "HTML(display(source_image, driving_video, predictions).to_html5_video())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3JAYGirDKr5"
      },
      "source": [
        "HTML(display_only_output(source_image, driving_video, predictions).to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAaQUtvtbmXC"
      },
      "source": [
        "**Now Let's make something walk!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPol8TWBtbWl"
      },
      "source": [
        "#download target image\n",
        "url = 'https://github.com/mitmedialab/MAS.S60.Fall2020/blob/master/homework/hw2-files/target_dinosaur.png?raw=true'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('target_dinosaur.png', 'wb').write(r.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgH1_8ncuseE"
      },
      "source": [
        "Image('/content/first-order-model/target_dinosaur.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAFE91_ruzdq"
      },
      "source": [
        "#download driving video\n",
        "import requests\n",
        "\n",
        "url = 'https://github.com/mitmedialab/MAS.S60.Fall2020/blob/master/homework/hw2-files/driving_house.mp4?raw=true'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "open('driving_house.mp4', 'wb').write(r.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY6UlkCMtgJV"
      },
      "source": [
        "#show driving video\n",
        "mp4 = open('/content/first-order-model/driving_house.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"<video width=400 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2OrrRfHcESs"
      },
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/u/0/uc?id=1_kb_on_hSM1a2ESL8O38pxT2xzN-7lkD'\n",
        "output = 'mgif-cpk.pth.tar'\n",
        "gdown.download(url, output, quiet=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJVCupEfbmEl"
      },
      "source": [
        "from demo import load_checkpoints\n",
        "generator, kp_detector = load_checkpoints(config_path='config/mgif-256.yaml', \n",
        "                            checkpoint_path='/content/first-order-model/mgif-cpk.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tnrS6VNfnwX"
      },
      "source": [
        "from demo import make_animation\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "\n",
        "source_image = imageio.imread('/content/first-order-model/target_dinosaur.png')\n",
        "driving_video = imageio.mimread('/content/first-order-model/driving_house.mp4', memtest=False)\n",
        "\n",
        "\n",
        "#Resize image and video to 256x256\n",
        "source_image = resize(source_image, (256, 256))[..., :3]\n",
        "driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
        "\n",
        "predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True,\n",
        "                             adapt_movement_scale=False)\n",
        "\n",
        "HTML(display(source_image, driving_video, predictions).to_html5_video())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQUPGQ8i8AN-"
      },
      "source": [
        "**Pro challenges for advanced students:**\n",
        "\n",
        "*   Create a deepfake of your younger/older self talking back to your present self!\n",
        "*   Create an interesting/thougthful outputs that utilize multiple algorithms that you encoutered in the previous homeworks!\n",
        "*   Use the real-time version of the First Order Model or other algorithm to transform yourself and come to the class in a character!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0EEuCquxEIM"
      },
      "source": [
        "**Congrats! You already finished the homework for this week :)**\n",
        "If you are interested in more cool stuffs, please check out the following codes:\n",
        "\n",
        "\n",
        "*   Motion Supervised co-part Segmentation (similar to First Order Model, but only transfer specific features to the target video) : https://github.com/AliaksandrSiarohin/motion-cosegmentation\n",
        "*   Latent Me (create a male/female, happy/sad, or older/younger version of yourself) : https://github.com/Puzer/stylegan-encoder/blob/master/Play_with_latent_directions.ipynb\n",
        "*   Wav2Lip (automatic lipsyncing) : https://github.com/Rudrabha/Wav2Lip, https://colab.research.google.com/drive/1tZpDWXz49W6wDcTprANRGLo2D_EbD5J8?usp=sharing\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}